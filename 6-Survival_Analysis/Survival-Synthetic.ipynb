{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "from sksurv.ensemble import GradientBoostingSurvivalAnalysis,RandomSurvivalForest\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lifelines.utils import concordance_index\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compare_models(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "    # Initialize the GBST survival regressor\n",
    "    gbst = GradientBoostingSurvivalAnalysis(n_estimators=100, random_state=20)\n",
    "    # Fit the model to the training data\n",
    "    gbst.fit(X_train, y_train)\n",
    "    # Predict the survival times for the testing data\n",
    "    survival_times_gbst = gbst.predict(X_test)\n",
    "\n",
    "    # Create an instance of the RandomSurvivalForest model\n",
    "    rsf = RandomSurvivalForest(n_estimators=100, random_state=20)\n",
    "    # Fit the model on the training data\n",
    "    rsf.fit(X_train, y_train)\n",
    "    # Predict the survival times for the testing data\n",
    "    survival_times_rsf = rsf.predict(X_test)\n",
    "\n",
    "    # Prepare the target variable for CoxPHSurvivalAnalysis\n",
    "    y_coxph = np.array(list(zip(y_train['event'], y_train['time'])), dtype=[('event', bool), ('time', float)])\n",
    "\n",
    "    # Create an instance of the CoxPHSurvivalAnalysis model with regularization\n",
    "    coxph = CoxPHSurvivalAnalysis(alpha=1e-9)\n",
    "    # Fit the model on the training data\n",
    "    coxph.fit(X_train, y_coxph)\n",
    "    # Predict the survival times for the testing data\n",
    "    survival_times_coxph = coxph.predict(X_test)\n",
    "\n",
    "    # Compute the concordance index to evaluate the model performance\n",
    "    c_index_gradient = concordance_index(y_test['time'], -survival_times_gbst, y_test['event'])\n",
    "    c_index_rf = concordance_index(y_test['time'], -survival_times_rsf, y_test['event'])\n",
    "    c_index_coxph = concordance_index(y_test['time'], -survival_times_coxph, y_test['event'])\n",
    "\n",
    "    return {\n",
    "        \"gradient\": c_index_gradient,\n",
    "        \"random_survival\": c_index_rf,\n",
    "        \"coxph\": c_index_coxph\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientAge</th>\n",
       "      <th>PatientGender</th>\n",
       "      <th>parentbreak</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>arthritis</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>oralster</th>\n",
       "      <th>smoke</th>\n",
       "      <th>obreak</th>\n",
       "      <th>event</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>15455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>76</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PatientAge  PatientGender  parentbreak  alcohol  arthritis  diabetes  \\\n",
       "0            53              1            0        0        0.0       0.0   \n",
       "1            85              1            0        0        0.0       1.0   \n",
       "2            90              1            0        0        1.0       0.0   \n",
       "3            81              1            0        0        0.0       0.0   \n",
       "4            60              1            1        0        0.0       1.0   \n",
       "..          ...            ...          ...      ...        ...       ...   \n",
       "795          83              1            4        0        0.0       0.0   \n",
       "796          60              1            0        0        0.0       0.0   \n",
       "797          76              2            0        0        0.0       0.0   \n",
       "798          61              1            2        1        0.0       0.0   \n",
       "799          69              1            0        0        0.0       0.0   \n",
       "\n",
       "     oralster  smoke  obreak  event   time  \n",
       "0           0      0       1   True    524  \n",
       "1           0      0       1   True   2046  \n",
       "2           0      0       1   True  15455  \n",
       "3           0      0       1   True   4354  \n",
       "4           0      0       1   True   2207  \n",
       "..        ...    ...     ...    ...    ...  \n",
       "795         4      0       1   True    579  \n",
       "796         0      0       1   True   5109  \n",
       "797         0      0       1   True   2125  \n",
       "798         0      1       1   True    518  \n",
       "799         0      1       1   True    483  \n",
       "\n",
       "[800 rows x 11 columns]"
      ]
     },
     "execution_count": 738,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data = pd.read_csv('IFR_Extract_with_selected_columns_15-5-23.csv')\n",
    "\n",
    "obreak_date = pd.to_datetime(data.obreak_date)\n",
    "datebone = pd.to_datetime(data.datebone)\n",
    "y = ( abs( datebone - obreak_date))\n",
    "X = data.drop([\"obreak_date\",\"datebone\"],axis=1)\n",
    "selectedColumns = [ 'PatientAge', \"PatientGender\",'parentbreak', 'alcohol',\n",
    "                'arthritis', 'diabetes',\n",
    "                'oralster', 'smoke', 'obreak']\n",
    "dropList = []\n",
    "for i in data:\n",
    "    if data[i].dtypes == 'O':\n",
    "        dropList.append(data[i].name)\n",
    "dropList.append(\"CompletedSurveyId\")\n",
    "dropList.append(\"PatientId\")\n",
    "X = data.drop(dropList,axis=1)\n",
    "X.fillna(0,inplace=True)\n",
    "y = pd.DataFrame({\"time\":y})\n",
    "\n",
    "y['event'] = y.time.apply(lambda x: x.days != 0 )\n",
    "structured_array = y.to_records(index=False)\n",
    "\n",
    "swapped = pd.DataFrame({\n",
    "    \"event\": y.event,\n",
    "    \"time\": y.time.apply(lambda x: x.days)\n",
    "})\n",
    "(swapped.event).value_counts()\n",
    "swapped.event = swapped.event.astype(bool)\n",
    "structured_array = np.rec.array(swapped.to_records(index=False))\n",
    "\n",
    "mergedBeforeEncoding = pd.concat([X[selectedColumns],swapped],axis=1)\n",
    "mergedBeforeEncoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of synthetic samples\n",
    "num_samples = 200\n",
    "\n",
    "# Get the column types for each column in mergedBeforeEncoding\n",
    "column_types = {}\n",
    "for column in mergedBeforeEncoding.columns:\n",
    "    column_types[column] = mergedBeforeEncoding[column].dtype\n",
    "\n",
    "# Shuffle the feature names\n",
    "feature_names = list(mergedBeforeEncoding.columns)\n",
    "random.shuffle(feature_names)\n",
    "\n",
    "# Initialize an empty DataFrame to store the selected features and their performance\n",
    "selected_features = pd.DataFrame(columns=[\"Feature\"])\n",
    "\n",
    "# Create a synthetic data DataFrame with the same columns as mergedBeforeEncoding\n",
    "synthetic_data = pd.DataFrame(columns=mergedBeforeEncoding.columns)\n",
    "\n",
    "# Generate synthetic data for each feature\n",
    "for feature in feature_names:\n",
    "    column_type = column_types[feature]\n",
    "\n",
    "    if column_type == bool:\n",
    "        synthetic_data[feature] = np.random.choice([False, True], size=num_samples)\n",
    "    else:\n",
    "        # Sample values from the existing data to maintain the distribution\n",
    "        existing_data_values = mergedBeforeEncoding[feature].dropna().values\n",
    "        synthetic_data[feature] = np.random.choice(existing_data_values, size=num_samples)\n",
    "\n",
    "    synthetic_data[feature] = synthetic_data[feature].astype(column_type)\n",
    "\n",
    "# Add additional columns to the synthetic data\n",
    "synthetic_data[\"obreak\"] = 1\n",
    "synthetic_data[\"event\"] = False\n",
    "synthetic_data[\"time\"] = 0\n",
    "\n",
    "augmented_data = pd.concat([mergedBeforeEncoding, synthetic_data], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "# Store the selected features\n",
    "selected_features[\"Feature\"] = feature_names\n",
    "\n",
    "cat_features = ['parentbreak', 'alcohol',\n",
    "                'arthritis', 'diabetes',\n",
    "                'oralster', 'smoke', 'obreak'\n",
    "                # These features were determined to apply minimal impact even\n",
    "                # 'respdisease', 'hbp','heartdisease',\n",
    "                # 'ptunsteady', 'wasfractdue2fall', 'cholesterol',\n",
    "                # 'ptfall', 'shoulder', 'wrist', 'bmdtest_10yr_caroc'\n",
    "                ]\n",
    "\n",
    "for feature in cat_features:\n",
    "    if augmented_data is not None:\n",
    "        if feature in augmented_data.columns:\n",
    "            cat_one_hot = pd.get_dummies(augmented_data[feature], prefix=f'{feature}', drop_first=False)\n",
    "            augmented_data = augmented_data.drop(feature, axis=1)\n",
    "            augmented_data = augmented_data.join(cat_one_hot)\n",
    "            \n",
    "X = augmented_data.drop(['event','time'],axis=1)\n",
    "y = augmented_data[['event','time']]\n",
    "\n",
    "y = np.rec.array(y.to_records(index=False))\n",
    "\n",
    "\n",
    "highest = 0.0\n",
    "best_feature = \"\"\n",
    "best_model_name = \"\"\n",
    "\n",
    "# for feature in X.columns:\n",
    "#     # Reshape the feature data to (n_samples, 1)\n",
    "#     reshaped_feature = X[feature].values.reshape(-1, 1)\n",
    "    \n",
    "#     outcome = compare_models(reshaped_feature, y)\n",
    "    \n",
    "#     if outcome['gradient'] > highest:\n",
    "#         highest = outcome['gradient']\n",
    "#         best_model_name = \"gradient\"\n",
    "#         best_feature = feature\n",
    "    \n",
    "#     if outcome['random_survival'] > highest:\n",
    "#         highest = outcome['random_survival']\n",
    "#         best_model_name = \"random_survival\"\n",
    "#         best_feature = feature\n",
    "#     if outcome['coxph'] > highest:\n",
    "#         highest = outcome['coxph']\n",
    "#         best_model_name = \"coxph\"\n",
    "#         best_feature = feature\n",
    "\n",
    "# print(\"Best feature:\", best_feature)\n",
    "# print(\"Best model:\", best_model_name)\n",
    "# print(\"Best c-index:\", highest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best feature combination: ['oralster_0', 'arthritis_0.0', 'parentbreak_4', 'smoke_1', 'parentbreak_1', 'parentbreak_0']\n",
      "Highest C-index: 0.5600078879905344\n",
      "Best Model: gradient\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def explore_feature_combinations(X, y, max_iterations=1000):\n",
    "    best_features = []\n",
    "    best_performance = 0\n",
    "    best_model_name = \"\"\n",
    "\n",
    "    current_features = set()\n",
    "    remaining_features = set(X.columns)\n",
    "\n",
    "    while remaining_features:\n",
    "        performance_gain = False\n",
    "        best_gain = 0\n",
    "        best_feature = None\n",
    "\n",
    "        for feature in remaining_features:\n",
    "            features_to_try = current_features | {feature}\n",
    "            X_subset = X[list(features_to_try)]\n",
    "            outcome = compare_models(X_subset, y)\n",
    "\n",
    "            if outcome['gradient'] > best_performance:\n",
    "                gain = outcome['gradient'] - best_performance\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_feature = feature\n",
    "                    best_model_name = 'gradient'\n",
    "\n",
    "            if outcome['random_survival'] > best_performance:\n",
    "                gain = outcome['random_survival'] - best_performance\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_feature = feature\n",
    "                    best_model_name = 'random_survival'\n",
    "\n",
    "            if outcome['coxph'] > best_performance:\n",
    "                gain = outcome['coxph'] - best_performance\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_feature = feature\n",
    "                    best_model_name = 'coxph'\n",
    "            \n",
    "        if best_feature is not None:\n",
    "            current_features.add(best_feature)\n",
    "            remaining_features.remove(best_feature)\n",
    "            best_performance += best_gain\n",
    "            performance_gain = True\n",
    "\n",
    "        if not performance_gain or len(current_features) >= max_iterations:\n",
    "            break\n",
    "\n",
    "    return best_model_name, list(current_features), best_performance\n",
    "\n",
    "# Call the function with a maximum of iterations equal to the total number of features\n",
    "best_model_name, best_features, best_performance = explore_feature_combinations(X, y, max_iterations=len(X.columns))\n",
    "\n",
    "print(\"Best feature combination:\", best_features)\n",
    "print(\"Highest C-index:\", best_performance)\n",
    "print(\"Best Model:\", best_model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sksurv.ensemble import RandomSurvivalForest\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from lifelines.utils import concordance_index\n",
    "\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# # Create an instance of the RandomSurvivalForest model\n",
    "# rsf = RandomSurvivalForest(n_estimators=100,random_state=20)\n",
    "\n",
    "# # Fit the model on the training data\n",
    "# rsf.fit(X_train, y_train)\n",
    "\n",
    "# # Calculate the baseline performance\n",
    "# baseline_score = concordance_index(y_test['time'], -rsf.predict(X_test), y_test['event'])\n",
    "\n",
    "# # Initialize an array to store the feature importances\n",
    "# feature_importances = np.zeros(X_train.shape[1])\n",
    "\n",
    "# # Perform feature importance calculation\n",
    "# for i in range(X_train.shape[1]):\n",
    "#     # Make a copy of the test set\n",
    "#     X_permuted = X_test.copy()\n",
    "\n",
    "#     # Permute the values of the feature at index i\n",
    "#     X_permuted.iloc[:, i] = np.random.permutation(X_permuted.iloc[:, i])\n",
    "\n",
    "#     # Calculate the permuted score\n",
    "#     permuted_score = concordance_index(y_test['time'], -rsf.predict(X_permuted), y_test['event'])\n",
    "\n",
    "#     # Calculate the feature importance as the difference between the baseline score and permuted score\n",
    "#     feature_importances[i] = baseline_score - permuted_score\n",
    "\n",
    "# # Normalize the feature importances\n",
    "# feature_importances /= np.sum(feature_importances)\n",
    "\n",
    "# # Print the feature importances\n",
    "# feature_names = X_train.columns\n",
    "\n",
    "# #for feature_name, importance in zip(feature_names, feature_importances):\n",
    "#     #print(f\"Feature: {feature_name}, Importance: {importance}\")\n",
    "\n",
    "# df = pd.DataFrame()\n",
    "# for name, importance in zip(feature_names, feature_importances):\n",
    "#     df = pd.concat([df, pd.DataFrame({'Feature Name': [name], 'Feature Importance': [importance]})], ignore_index=True)\n",
    "\n",
    "# df = df.sort_values('Feature Importance', ascending=False)\n",
    "\n",
    "# df\n",
    "\n",
    "# # Calculate the c-index on the test set\n",
    "# c_index = concordance_index(y_test['time'], -rsf.predict(X_test), y_test['event'])\n",
    "# print(\"C-index:\", c_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
