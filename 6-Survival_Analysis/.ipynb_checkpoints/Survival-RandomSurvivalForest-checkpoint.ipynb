{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    388\n",
       "0.0    201\n",
       "2.0     91\n",
       "3.0     10\n",
       "Name: fxworried, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('IFR_Extract_with_selected_columns_15-5-23.csv')\n",
    "\n",
    "obreak_date = pd.to_datetime(data.obreak_date)\n",
    "datebone = pd.to_datetime(data.datebone)\n",
    "y = ( abs( datebone - obreak_date))\n",
    "X = pd.DataFrame({\n",
    "    \"PatientAge\": data.PatientAge,\n",
    "    \"PatientGender\": data.PatientGender,\n",
    "    \n",
    "})\n",
    "y\n",
    "data['fxworried'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X = data.drop(['PostalCode','DateSurveyed','obreak_date','datebone','obone_text','rxother_text'\n",
    "# ,'rx2_other_text','norxo_text','obone_text','obreak_obone_text'],axis=1)\n",
    "\n",
    "dropList = []\n",
    "for i in data:\n",
    "    if data[i].dtypes == 'O':\n",
    "        dropList.append(data[i].name)\n",
    "dropList.append(\"CompletedSurveyId\")\n",
    "dropList.append(\"PatientId\")\n",
    "X = data.drop(dropList,axis=1)\n",
    "X.fillna(0,inplace=True)\n",
    "y = pd.DataFrame({\"time\":y})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    751\n",
       "True      49\n",
       "Name: time, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.time\n",
    "\n",
    "y['event'] = y.time.apply(lambda x: x.days != 0 )\n",
    "structured_array = y.to_records(index=False)\n",
    "\n",
    "swapped = pd.DataFrame({\n",
    "    \"event\": y.event,\n",
    "    \"time\": y.time.apply(lambda x: x.days)\n",
    "})\n",
    "(swapped.time < 100).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     346\n",
       "8     233\n",
       "6      73\n",
       "9      51\n",
       "7      49\n",
       "5      35\n",
       "4       6\n",
       "10      4\n",
       "2       3\n",
       "Name: specialistReferral, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swapped.event = swapped.event.astype(bool)\n",
    "swapped.event\n",
    "structured_array = np.rec.array(swapped.to_records(index=False))\n",
    "X['specialistReferral'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sksurv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msksurv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomSurvivalForest\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlifelines\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m concordance_index\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sksurv'"
     ]
    }
   ],
   "source": [
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lifelines.utils import concordance_index\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, structured_array, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an instance of the RandomSurvivalForest model\n",
    "model = RandomSurvivalForest(random_state=10)\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the baseline performance\n",
    "baseline_score = concordance_index(y_test['time'], -model.predict(X_test), y_test['event'])\n",
    "\n",
    "# Initialize an array to store the feature importances\n",
    "feature_importances = np.zeros(X_train.shape[1])\n",
    "\n",
    "# Perform feature importance calculation\n",
    "for i in range(X_train.shape[1]):\n",
    "    # Make a copy of the test set\n",
    "    X_permuted = X_test.copy()\n",
    "\n",
    "    # Permute the values of the feature at index i\n",
    "    X_permuted.iloc[:, i] = np.random.permutation(X_permuted.iloc[:, i])\n",
    "\n",
    "    # Calculate the permuted score\n",
    "    permuted_score = concordance_index(y_test['time'], -model.predict(X_permuted), y_test['event'])\n",
    "\n",
    "    # Calculate the feature importance as the difference between the baseline score and permuted score\n",
    "    feature_importances[i] = baseline_score - permuted_score\n",
    "\n",
    "# Normalize the feature importances\n",
    "feature_importances /= np.sum(feature_importances)\n",
    "\n",
    "# Print the feature importances\n",
    "feature_names = X_train.columns\n",
    "\n",
    "#for feature_name, importance in zip(feature_names, feature_importances):\n",
    "    #print(f\"Feature: {feature_name}, Importance: {importance}\")\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for name, importance in zip(feature_names, feature_importances):\n",
    "    df = pd.concat([df, pd.DataFrame({'Feature Name': [name], 'Feature Importance': [importance]})], ignore_index=True)\n",
    "\n",
    "df = df.sort_values('Feature Importance', ascending=False)\n",
    "\n",
    "df\n",
    "\n",
    "# Calculate the c-index on the test set\n",
    "c_index = concordance_index(y_test['time'], -model.predict(X_test), y_test['event'])\n",
    "print(\"C-index:\", c_index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deleted_columns = []\n",
    "cutoff = 0.1\n",
    "while(len(deleted_columns) < 180):\n",
    "        deleted_columns = []\n",
    "        for i in range(len(feature_importances)):\n",
    "                if feature_importances[i] >= 0 and feature_importances[i] < cutoff:\n",
    "                        deleted_columns.append(feature_names[i])    \n",
    "                elif feature_importances[i] < 0 and feature_importances[i] > -cutoff:\n",
    "                        deleted_columns.append(feature_names[i]) \n",
    "        cutoff += 0.1\n",
    "X = data.drop((deleted_columns + dropList),axis=1)\n",
    "\n",
    "X = X.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "estimator = CoxPHSurvivalAnalysis()\n",
    "estimator.fit(X, structured_array)\n",
    "\n",
    "# Calculate the c-index on the test set\n",
    "c_index = concordance_index(structured_array['time'], -estimator.predict(X), structured_array['event'])\n",
    "print(\"C-index:\", c_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(estimator.coef_, index=X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pred_surv = estimator.predict_survival_function(X.loc[:15])\n",
    "time_points = np.arange(1, 1000)\n",
    "for i, surv_func in enumerate(pred_surv):\n",
    "    plt.step(time_points, surv_func(time_points), where=\"post\",\n",
    "             label=\"Sample %d\" % (i + 1))\n",
    "plt.ylabel(\"est. probability of survival $\\hat{S}(t)$\")\n",
    "plt.xlabel(\"time $t$\")\n",
    "plt.legend(loc=\"best\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
